{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading PlanetScope Scenes using Planet Orders API\n",
    "---\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "By the end of this exercise, you should be able:\n",
    "* to access Planet Orders API\n",
    "* to search for PlanetScope Scenes given a set of rules (e.g., using a area of interest to filter out images)\n",
    "* to download multiple PlanetScope Scenes using Planet Orders API\n",
    "---\n",
    "\n",
    "We will continue to use Lake Raleigh as our area of interest (AOI). Planet has multiple [APIs](https://developers.planet.com/docs/apis/) that serve different purposes. In this exercise, we will use the [Data API](https://developers.planet.com/docs/apis/data/) and the [Orders API](https://developers.planet.com/apis/orders/). The Data API provides the [Quick Search](https://developers.planet.com/docs/apis/data/quick-saved-search/) functionality, which is the easiest way to search the Planet catalog. The Orders API is used to access analysis ready data (e.g., surface reflectance imagery) and have the images delivered directly to our local or cloud storage.\n",
    "\n",
    "The Orders API makes it easier to create pipelines to continuously downloading imagery for processing and analysis. For instance, you can manually download imagery using [Planet Explorer](https://developers.planet.com/docs/apps/explorer/) or Planet [QGIS](https://developers.planet.com/docs/integrations/qgis/) or [ArcGIS](https://developers.planet.com/docs/integrations/arcgis/); nonetheless, this quickly becomes a burden if you have to download thousands of images for multiple AOIs!   \n",
    "\n",
    "#### Getting Started with Planet APIs\n",
    "\n",
    "To use any Planet API, you'll need an API key. API keys are available to all registered users with active Planet accounts. Once you signed up for the [Education and Research Program](https://www.planet.com/markets/education-and-research/) account, you will need to get your API key. To do so, log in to your account at [planet.com/account](https://www.planet.com/account/). Please note it may take up to two weeks for your account to be activated under the Education and Research Program.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src='imgs/planet-api-key.png' width='1200' /> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import geojson\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from shapely import geometry as sgeom\n",
    "from requests.auth import HTTPBasicAuth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication\n",
    "\n",
    "You will need your Planet API Key here. The easiest way to authenticate is to simply copy and past the API key into the Jupyter Notebook—we will use this method to make it simpler. Nonetheless, this is not recommended, as this document may be public (i.e., in your GitHub account) or you may share it with others. Therefore, for future reference, it is recommended that you store your API key as an environment variable, which you can read more about [here](https://www.nylas.com/blog/making-use-of-environment-variables-in-python/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PL_API_KEY = 'enter your api key here'\n",
    "\n",
    "# URL to access the Orders API\n",
    "orders_url = 'https://api.planet.com/compute/ops/orders/v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To communicate with the API we will use the python package `requests`. First, we will make sure that the authentication and communication are working as expected. We expect to get a response code of `200` from this API call. To troubleshoot other response codes, please check [here](https://developers.planet.com/docs/orders/reference/#operation/listOrders)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth = HTTPBasicAuth(PL_API_KEY, '')\n",
    "response = requests.get(orders_url, auth=auth)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the communication is working fine, we will build up a request to search for images. We will load our geojson (AOI for Lake Raleigh), and define certain parameters, for example, cloud cover, dates, etc.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the coordinates (area of interest, AOI) from the lake-raleigh.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Polygon',\n",
       " 'coordinates': [[[-78.687957, 35.769435],\n",
       "   [-78.675624, 35.769435],\n",
       "   [-78.675691, 35.76139],\n",
       "   [-78.688092, 35.761281],\n",
       "   [-78.687957, 35.769435]]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('aoi/lake-raleigh.geojson') as f:\n",
    "    gj = geojson.load(f)\n",
    "\n",
    "coords = gj['features'][0]['geometry']['coordinates'][0]\n",
    "aoi_geom = {\"type\": \"Polygon\", \"coordinates\": coords}\n",
    "aoi_geom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the general objects for imagery search\n",
    "\n",
    "First, we need to define a time frame for our search at Planet's catalog, this includes a starting and an ending date. Then, we will define a cloud cover threshold (from 0 to 1) with a less than or equal (lte) rule, and the type of imagery that we want. Planet has several item [types](https://developers.planet.com/docs/apis/data/items-assets/), we will be using [PSScenes](https://developers.planet.com/docs/data/psscene/), and we will download the following asset types: `'ortho_analytic_4b'` and `'ortho_udm2'`. See all available asset types [here](https://developers.planet.com/docs/data/psscene/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_date, end_date = '2021-11-14', '2021-11-15'\n",
    "cloud_cover = 0.05  # 5% of cloud cover allowed\n",
    "item_type = 'PSScene'\n",
    "asset_one, asset_two = 'ortho_analytic_4b', 'ortho_udm2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the parameters, we need to pass them along as dictionaries to create the request body that we will send to the API. We have a total of four filters—geometry, date, cloud and asset type—in the form of dictionaries. More examples can be found [here](https://developers.planet.com/docs/apis/data/searches-filtering/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_types': ['PSScene'],\n",
       " 'filter': {'type': 'AndFilter',\n",
       "  'config': [{'type': 'GeometryFilter',\n",
       "    'field_name': 'geometry',\n",
       "    'config': {'type': 'Polygon',\n",
       "     'coordinates': [[[-78.687957, 35.769435],\n",
       "       [-78.675624, 35.769435],\n",
       "       [-78.675691, 35.76139],\n",
       "       [-78.688092, 35.761281],\n",
       "       [-78.687957, 35.769435]]]}},\n",
       "   {'type': 'DateRangeFilter',\n",
       "    'field_name': 'acquired',\n",
       "    'config': {'gte': '2021-11-14T00:00:00.000Z',\n",
       "     'lte': '2021-11-15T23:59:59.999Z'}},\n",
       "   {'type': 'RangeFilter',\n",
       "    'field_name': 'cloud_cover',\n",
       "    'config': {'lte': 0.05}},\n",
       "   {'type': 'AndFilter',\n",
       "    'config': [{'type': 'AssetFilter', 'config': ['ortho_analytic_4b']},\n",
       "     {'type': 'AssetFilter', 'config': ['ortho_udm2']}]}]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometry_filter = {\"type\": \"GeometryFilter\",\n",
    "                   \"field_name\": \"geometry\",\n",
    "                   \"config\": aoi_geom}\n",
    "\n",
    "date_filter = {\"type\": \"DateRangeFilter\",\n",
    "               \"field_name\": \"acquired\",\n",
    "               \"config\": {\"gte\": \"{}T00:00:00.000Z\".format(st_date), \"lte\": \"{}T23:59:59.999Z\".format(end_date)}}\n",
    "\n",
    "cloud_filter = {\"type\": \"RangeFilter\",\n",
    "                \"field_name\": \"cloud_cover\",\n",
    "                \"config\": {\"lte\": cloud_cover}}\n",
    "\n",
    "asset_type = {\"type\": \"AndFilter\",\n",
    "              \"config\": [{\"type\": \"AssetFilter\", \"config\": [asset_one]},\n",
    "                         {\"type\": \"AssetFilter\", \"config\": [asset_two]}]}\n",
    "\n",
    "combined_filter = {\"type\": \"AndFilter\",\n",
    "                   \"config\": [geometry_filter, date_filter, cloud_filter, asset_type]}\n",
    "\n",
    "search_request = {\"item_types\": [item_type],\n",
    "                  \"filter\": combined_filter}\n",
    "search_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posting the search request\n",
    "Now that we created the search request with the imagery filtering rules that we want, we will build a `post` request to interact with the API. Again, if sucessfull, we should expect `200` as the post response.\n",
    "\n",
    "To help us with the API output, we will leverage the two functions described below: `fetch_page` and `get_meta`. The first function will allow us to paginate over our search in the API. Briefly, if the output of our search has more than 250 elements (i.e., more than 250 images based on our filters), we will have multiple pages (each page has a link). Hence, we need to get the information from the first page, applying `get_meta`, and then, we need to move on to the next page (paginate!), and we will paginate using `fetch_page`. In case we have less than 250 elements per search, then we only have one page, therefore, we do not need to paginate.\n",
    "\n",
    "As a last step, we will get the geometry (extent) of the image using `shapely_geom` as a shapely object. This is necessary to calculate the percentage of overlap betweent the image and our AOI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not worry for now if you do not understand the 3 functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(page_info):\n",
    "    \"\"\"Transforms request .json response into pd.DataFrame() and get the images metadata information.\n",
    "    \"\"\"\n",
    "    frame = pd.DataFrame([{**{'image_id': img['id']}, **img['properties']} for img in page_info['features']])\n",
    "    return frame\n",
    "\n",
    "\n",
    "def shapely_geom(geom):\n",
    "    \"\"\"Converts the AOI geometry to a shapely structure.\n",
    "    \"\"\"\n",
    "    aoi = {u'geometry': {u'type': u'Polygon', u'coordinates': geom['coordinates']}}\n",
    "    aoi_shape = sgeom.shape(aoi['geometry'])\n",
    "    return aoi_shape\n",
    "\n",
    "\n",
    "def fetch_page(url, _list):\n",
    "    \"\"\"Paginates over API request if more than 250 results are found on Planet Catalog.\n",
    "    \"\"\"\n",
    "    s = requests.get(url, auth=auth)\n",
    "    res_code = s.status_code\n",
    "\n",
    "    while res_code == 429:\n",
    "        print('rate of requests too high! sleep 2s...')\n",
    "        time.sleep(2)\n",
    "        s = requests.get(url, auth=auth)\n",
    "        res_code = s.status_code\n",
    "\n",
    "    result = s.json()\n",
    "    metadata = get_meta(result)\n",
    "    metadata['geom'] = [shapely_geom(geom['geometry']) for geom in result['features']]\n",
    "    _list.append(metadata)\n",
    "\n",
    "    next_url = result[\"_links\"].get(\"_next\")\n",
    "\n",
    "    if next_url:\n",
    "        fetch_page(next_url, _list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now building the post request to interact with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 image(s) matching the filters.\n"
     ]
    }
   ],
   "source": [
    "url_quick_search = \"https://api.planet.com/data/v1/quick-search\"  # url to search for imagery\n",
    "res = requests.post(url_quick_search, auth=(PL_API_KEY, ''), json=search_request)\n",
    "\n",
    "if not res.status_code == 200:\n",
    "    print(res.text)\n",
    "else:\n",
    "    # get results from post and link of the 1st page\n",
    "    post_result = res.json()\n",
    "    link_first_page = post_result['_links']['_first']\n",
    "\n",
    "    _meta = []\n",
    "    fetch_page(link_first_page, _meta)  # paginates if necessary and stores metadata to _meta\n",
    "\n",
    "    if len(_meta) > 0:\n",
    "        metadata = pd.concat(_meta)\n",
    "    else:\n",
    "        metadata = _meta[0]\n",
    "\n",
    "    image_ids = metadata.image_id.tolist()\n",
    "\n",
    "    if len(image_ids) == 0:\n",
    "        print(\"No suitable images were found. Double check filters, including asset_types.\")\n",
    "    else:\n",
    "        print(\"Found {} image(s) matching the filters.\".format(len(image_ids)))\n",
    "        metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining our search\n",
    "\n",
    "When using Planet Explorer, we are able to set an AOI coverage (%) filter, which tells us how much of the AOI is covered by the image. This is very important because it enables us to filter out images that cover only a small part of our AOI. For instance, see the example below, in which only the blue shaded part of the AOI is covered by the image. The Orders API does not have a built in filter to only select images that overlap with a large part of our AOI, therefore, we will create our own method to filter out those images.\n",
    "\n",
    "We will use the image metadata from our search to calculate the percentage of overlap between the image extent and the AOI extent. \n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src='imgs/planet-aoi-coverage.png' width='1200' /> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>acquired</th>\n",
       "      <th>anomalous_pixels</th>\n",
       "      <th>clear_confidence_percent</th>\n",
       "      <th>clear_percent</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>cloud_percent</th>\n",
       "      <th>ground_control</th>\n",
       "      <th>gsd</th>\n",
       "      <th>heavy_haze_percent</th>\n",
       "      <th>...</th>\n",
       "      <th>snow_ice_percent</th>\n",
       "      <th>strip_id</th>\n",
       "      <th>sun_azimuth</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>updated</th>\n",
       "      <th>view_angle</th>\n",
       "      <th>visible_confidence_percent</th>\n",
       "      <th>visible_percent</th>\n",
       "      <th>geom</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211114_160039_40_2402</td>\n",
       "      <td>2021-11-14T16:00:39.405833Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5098663</td>\n",
       "      <td>162.6</td>\n",
       "      <td>33.9</td>\n",
       "      <td>2021-11-16T17:32:46Z</td>\n",
       "      <td>4.1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>POLYGON ((-78.96215928689067 35.92796872381647...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_id                     acquired  anomalous_pixels  \\\n",
       "0  20211114_160039_40_2402  2021-11-14T16:00:39.405833Z               0.0   \n",
       "\n",
       "   clear_confidence_percent  clear_percent  cloud_cover  cloud_percent  \\\n",
       "0                      99.0          100.0          0.0            0.0   \n",
       "\n",
       "  ground_control  gsd  heavy_haze_percent  ... snow_ice_percent strip_id  \\\n",
       "0           True  4.0                 0.0  ...              0.0  5098663   \n",
       "\n",
       "   sun_azimuth  sun_elevation               updated view_angle  \\\n",
       "0        162.6           33.9  2021-11-16T17:32:46Z        4.1   \n",
       "\n",
       "  visible_confidence_percent visible_percent  \\\n",
       "0                       73.0           100.0   \n",
       "\n",
       "                                                geom coverage  \n",
       "0  POLYGON ((-78.96215928689067 35.92796872381647...    100.0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform aoi_geom to shapely shape\n",
    "aoi_shape = shapely_geom(aoi_geom)\n",
    "\n",
    "_cov = []\n",
    "for index, image_shape in enumerate(metadata.geom.tolist()):\n",
    "    coverage = np.round((aoi_shape.intersection(image_shape).area / aoi_shape.area) * 100, 2)\n",
    "    _cov.append(coverage)\n",
    "\n",
    "metadata['coverage'] = _cov\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering out images that did not cover 90% or more of our AOI, were are left with 1 image(s).\n"
     ]
    }
   ],
   "source": [
    "coverage_thresh = 90\n",
    "images_subset = metadata[metadata.coverage >= coverage_thresh]\n",
    "print(f'After filtering out images that did not cover {coverage_thresh}% or more of our AOI, were are left with {len(images_subset)} image(s).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have images that were collected on the same day, within minutes or hours apart. After we applied our AOI coverage filter, all images that are left cover >= 90% of our AOI. In this case, we could use another set of rules, based on the images' metadata, to decide which images to chose from those that were collected on the same day. To make it simpler, we will choose the image that was collected first, using the `'acquired'` column from `images_subset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering out images that were collected on the same day, were are left with 1 image(s).\n"
     ]
    }
   ],
   "source": [
    "dates = [d[0:10] for d in images_subset.acquired.tolist()]\n",
    "images_subset = images_subset.assign(dates=dates)  # create new column called 'dates' using assign\n",
    "\n",
    "# drop duplicates using column 'dates'\n",
    "images_subset = images_subset.drop_duplicates(subset='dates', keep='first')\n",
    "print(f'After filtering out images that were collected on the same day, were are left with {len(images_subset)} image(s).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place imagery order, activate items and download imagery\n",
    "\n",
    "To download the images, we need their image id, which is available within the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general objects\n",
    "image_ids = images_subset.image_id.tolist()  # images that will be downloaded\n",
    "url_orders = 'https://api.planet.com/compute/ops/orders/v2'  # POST\n",
    "headers = {'content-type': 'application/json'}\n",
    "order_name = 'lake_raleigh'\n",
    "save_path = os.path.join(os.getcwd(), 'results')  # you can change if you would like to save in another folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and posting the payload for imagery download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order succesfully placed with order id ed4b1863-0d9b-4766-b20b-1a7f9519437b\n",
      "Order url: \n",
      " https://api.planet.com/compute/ops/orders/v2/ed4b1863-0d9b-4766-b20b-1a7f9519437b\n"
     ]
    }
   ],
   "source": [
    "# create post payload\n",
    "payload = {\n",
    "    \"name\": order_name,\n",
    "    \"order_type\": \"partial\",\n",
    "    \"products\": [{\n",
    "        \"item_ids\": image_ids,\n",
    "        \"item_type\": 'PSScene',\n",
    "        \"product_bundle\": 'analytic_sr_udm2'\n",
    "    }],\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"harmonize\": {\n",
    "                \"target_sensor\": \"Sentinel-2\"\n",
    "            }},\n",
    "        {\n",
    "            \"clip\": {\n",
    "                \"aoi\": aoi_geom  # Lake Raleigh extent\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"delivery\": {},\n",
    "    \"notifications\": {\n",
    "        \"email\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url_orders, data=json.dumps(payload), auth=(PL_API_KEY, ''), headers=headers)\n",
    "\n",
    "if response.status_code == 202:\n",
    "    print(\"Order succesfully placed with order id {}\".format(response.json()[\"id\"]))\n",
    "    order_id = response.json()[\"id\"]\n",
    "    order_url = url_orders + \"/\" + order_id\n",
    "    print(f'Order url: \\n {order_url}')\n",
    "else:\n",
    "    print(\"Order failed with error {}\".format(response.json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the order status, polling for success, and downloading the images.\n",
    "This function below will take a while to run, it took ~20 min on my laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polling order..\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: running\n",
      "Current state: success\n"
     ]
    }
   ],
   "source": [
    "def poll_for_success(order_url, num_loops=100):\n",
    "    print(\"Polling order..\")\n",
    "    count = 0\n",
    "    while count < num_loops:\n",
    "        count += 1\n",
    "        r = requests.get(order_url, auth=(PL_API_KEY, ''))\n",
    "        response = r.json()\n",
    "        state = response[\"state\"]\n",
    "        print(\"Current state: {}\".format(state))\n",
    "        end_states = [\"success\", \"failed\", \"partial\"]\n",
    "        if state in end_states:\n",
    "            results = response[\"_links\"][\"results\"]\n",
    "            results_name = [r[\"name\"] for r in results]\n",
    "            results_urls = [r[\"location\"] for r in results]\n",
    "            break\n",
    "        time.sleep(60)\n",
    "\n",
    "    return [results_name, results_urls]\n",
    "\n",
    "location_url_list = poll_for_success(order_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the images once the order is ready (current state = *'success'*).  \n",
    "\n",
    "We will download the images and save them at the `'save_path'` directory that we defined above. The function `download_results()` will create the `'save_path'` directory if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 items to download\n",
      "Downloading : 20211114_160039_40_2402_3B_AnalyticMS_metadata_clip.xml\n",
      "Downloading : 20211114_160039_40_2402_3B_udm2_clip.tif\n",
      "Downloading : 20211114_160039_40_2402_3B_AnalyticMS_SR_harmonized_clip.tif\n",
      "Downloading : 20211114_160039_40_2402_metadata.json\n",
      "Downloading : manifest.json\n"
     ]
    }
   ],
   "source": [
    "def download_results(results_urls, results_name, overwrite=False):\n",
    "    print(\"{} items to download\".format(len(results_urls)))\n",
    "    for url, name in zip(results_urls, results_name):\n",
    "        path = Path(save_path + f'/images/{order_name}/{name}')\n",
    "        if overwrite or not path.exists():\n",
    "            print(\"Downloading : {}\".format(os.path.basename(path)))\n",
    "            r = requests.get(url, allow_redirects=True)\n",
    "            path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            open(path, \"wb\").write(r.content)\n",
    "        else:\n",
    "            print(\"{} :Already exists, skipping\".format(os.path.basename(path)))\n",
    "\n",
    "\n",
    "if len(location_url_list) > 0:\n",
    "    results_names = location_url_list[0]\n",
    "    results_urls = location_url_list[1]\n",
    "    download_results(results_urls, results_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('NR491')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d767317ec53fc89358759cb941419f290fac210382fd1fe904dda98b050cea6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
